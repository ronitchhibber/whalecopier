"""
Find whales by analyzing ON-CHAIN data from Polygon blockchain.
No Polymarket APIs - pure blockchain analysis.
"""

import os
import sys
import requests
import time
from collections import defaultdict
from datetime import datetime
from sqlalchemy import create_engine
from sqlalchemy.orm import Session

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from libs.common.models import Whale
from dotenv import load_dotenv

load_dotenv()

DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://trader:changeme123@localhost:5432/polymarket_trader')
engine = create_engine(DATABASE_URL)

# Polymarket contracts on Polygon
CTF_EXCHANGE = "0x4bFb41d5B3570DeFd03C39a9A4D8dE6Bd8B8982E"
CONDITIONAL_TOKENS = "0x4D97DCd97eC945f40cF65F87097ACe5EA0476045"

# Public Polygon RPC endpoints
POLYGON_RPCS = [
    "https://polygon-rpc.com",
    "https://rpc-mainnet.matic.network",
    "https://rpc-mainnet.maticvigil.com",
    "https://polygon-mainnet.public.blastapi.io",
]

POLYGONSCAN_API_KEY = "YourAPIKeyToken"  # Free tier available


def query_thegraph_subgraph():
    """Query The Graph for Polymarket on-chain data."""
    print("\n" + "="*80)
    print("üìä QUERYING THE GRAPH SUBGRAPH")
    print("="*80)

    # Try multiple subgraph endpoints
    subgraphs = [
        "https://api.thegraph.com/subgraphs/name/tokenunion/polymarket-matic",
        "https://api.thegraph.com/subgraphs/name/polymarket/polymarket",
        "https://api.studio.thegraph.com/query/polymarket",
    ]

    query = """
    {
      users(first: 100, orderBy: totalVolume, orderDirection: desc, where: {totalVolume_gt: "100000"}) {
        id
        totalVolume
        totalTrades
        positions(first: 1) {
          id
        }
      }

      trades(first: 500, orderBy: timestamp, orderDirection: desc) {
        id
        user {
          id
        }
        amount
        price
        timestamp
      }
    }
    """

    for subgraph_url in subgraphs:
        try:
            print(f"\n  Trying: {subgraph_url[:50]}...")

            response = requests.post(
                subgraph_url,
                json={'query': query},
                headers={'Content-Type': 'application/json'},
                timeout=20
            )

            if response.status_code == 200:
                data = response.json()

                if 'data' in data and 'users' in data['data']:
                    users = data['data']['users']
                    trades = data['data'].get('trades', [])

                    print(f"  ‚úÖ Found {len(users)} users, {len(trades)} trades")

                    # Process users
                    whales = []
                    for user in users:
                        address = user['id'].lower()
                        volume = float(user.get('totalVolume', 0))
                        num_trades = int(user.get('totalTrades', 0))

                        if volume < 100000:  # Skip < $100k
                            continue

                        whales.append({
                            'address': address,
                            'volume': volume,
                            'trades': num_trades,
                            'pnl': volume * 0.04,  # Estimate 4% profit
                        })

                    # Analyze trades to get recent activity
                    trader_activity = defaultdict(lambda: {'recent_trades': 0, 'recent_volume': 0})

                    for trade in trades:
                        user_id = trade.get('user', {}).get('id', '').lower()
                        amount = float(trade.get('amount', 0))

                        if user_id:
                            trader_activity[user_id]['recent_trades'] += 1
                            trader_activity[user_id]['recent_volume'] += amount

                    # Enhance whale data with recent activity
                    for whale in whales:
                        addr = whale['address']
                        if addr in trader_activity:
                            whale['recent_trades'] = trader_activity[addr]['recent_trades']
                            whale['active'] = True

                    print(f"  ‚úÖ Extracted {len(whales)} whales with >$100k volume")
                    return whales

                elif 'errors' in data:
                    print(f"  ‚ùå GraphQL errors: {data['errors']}")

        except Exception as e:
            print(f"  ‚ùå Error: {e}")

    return []


def query_polygonscan_for_traders():
    """Use PolygonScan API to find traders interacting with CTF Exchange."""
    print("\n" + "="*80)
    print("üîó QUERYING POLYGONSCAN FOR ON-CHAIN TRADERS")
    print("="*80)

    trader_stats = defaultdict(lambda: {
        'txs': 0,
        'total_value': 0,
        'first_seen': None,
        'last_seen': None,
    })

    # Get recent transactions to CTF Exchange
    params = {
        'module': 'account',
        'action': 'txlist',
        'address': CTF_EXCHANGE,
        'startblock': 0,
        'endblock': 99999999,
        'page': 1,
        'offset': 10000,
        'sort': 'desc',
        'apikey': POLYGONSCAN_API_KEY
    }

    try:
        print(f"\n  Fetching transactions to CTF Exchange ({CTF_EXCHANGE})...")

        response = requests.get(
            'https://api.polygonscan.com/api',
            params=params,
            timeout=30
        )

        if response.status_code == 200:
            data = response.json()

            if data.get('status') == '1':
                txs = data.get('result', [])
                print(f"  ‚úÖ Found {len(txs)} transactions")

                for tx in txs:
                    trader = tx.get('from', '').lower()
                    value = int(tx.get('value', 0)) / 1e18
                    timestamp = int(tx.get('timeStamp', 0))

                    if not trader or trader == '0x0000000000000000000000000000000000000000':
                        continue

                    # Skip if error
                    if tx.get('isError') == '1':
                        continue

                    trader_stats[trader]['txs'] += 1
                    trader_stats[trader]['total_value'] += value

                    if trader_stats[trader]['first_seen'] is None:
                        trader_stats[trader]['first_seen'] = timestamp
                        trader_stats[trader]['last_seen'] = timestamp
                    else:
                        trader_stats[trader]['first_seen'] = min(trader_stats[trader]['first_seen'], timestamp)
                        trader_stats[trader]['last_seen'] = max(trader_stats[trader]['last_seen'], timestamp)

                # Convert to whale list
                whales = []
                sorted_traders = sorted(
                    trader_stats.items(),
                    key=lambda x: x[1]['txs'],
                    reverse=True
                )

                for address, stats in sorted_traders[:100]:  # Top 100
                    # Estimate volume from transaction count
                    estimated_volume = stats['txs'] * 5000  # Avg $5k per tx

                    if estimated_volume < 100000:
                        continue

                    # Calculate time active
                    if stats['first_seen'] and stats['last_seen']:
                        days_active = (stats['last_seen'] - stats['first_seen']) / 86400
                    else:
                        days_active = 1

                    whales.append({
                        'address': address,
                        'volume': estimated_volume,
                        'trades': stats['txs'],
                        'pnl': estimated_volume * 0.03,
                        'days_active': days_active,
                    })

                print(f"  ‚úÖ Extracted {len(whales)} high-activity traders")
                return whales

    except Exception as e:
        print(f"  ‚ùå Error: {e}")

    return []


def query_dune_analytics():
    """Try to fetch data from public Dune Analytics endpoints."""
    print("\n" + "="*80)
    print("üìà QUERYING DUNE ANALYTICS")
    print("="*80)

    # Public Dune query endpoints (some dashboards expose CSV exports)
    dune_endpoints = [
        "https://dune.com/api/v1/query/3284657/results",  # Example Polymarket query
        "https://api.dune.com/api/v1/query/3284657/results",
    ]

    for endpoint in dune_endpoints:
        try:
            print(f"\n  Trying: {endpoint[:50]}...")

            response = requests.get(
                endpoint,
                headers={'User-Agent': 'Mozilla/5.0'},
                timeout=15
            )

            if response.status_code == 200:
                data = response.json()

                # Try to parse results
                if 'result' in data and 'rows' in data['result']:
                    rows = data['result']['rows']
                    print(f"  ‚úÖ Found {len(rows)} rows of data")

                    whales = []
                    for row in rows:
                        # Extract relevant fields (field names vary by query)
                        address = (row.get('trader') or row.get('address') or row.get('user', '')).lower()
                        volume = float(row.get('volume', 0) or row.get('total_volume', 0) or 0)

                        if not address or not address.startswith('0x') or volume < 100000:
                            continue

                        whales.append({
                            'address': address,
                            'volume': volume,
                            'trades': int(row.get('trades', volume / 1000)),
                            'pnl': float(row.get('pnl', volume * 0.03)),
                        })

                    if whales:
                        print(f"  ‚úÖ Extracted {len(whales)} whales from Dune")
                        return whales

        except Exception as e:
            print(f"  ‚ùå Error: {e}")

    return []


def fetch_from_github_curated_lists():
    """Check GitHub for curated lists of Polymarket whale addresses."""
    print("\n" + "="*80)
    print("üìö SEARCHING GITHUB FOR CURATED WHALE LISTS")
    print("="*80)

    # Search GitHub for Polymarket whale lists
    github_searches = [
        "https://api.github.com/search/code?q=polymarket+whale+addresses",
        "https://api.github.com/search/repositories?q=polymarket+leaderboard",
    ]

    for search_url in github_searches:
        try:
            print(f"\n  Searching: {search_url[:60]}...")

            response = requests.get(
                search_url,
                headers={'Accept': 'application/vnd.github.v3+json'},
                timeout=15
            )

            if response.status_code == 200:
                data = response.json()
                items = data.get('items', [])

                print(f"  ‚úÖ Found {len(items)} results")

                # Could download and parse files, but would need more processing
                # For now, just report what we found
                for item in items[:5]:
                    print(f"    - {item.get('name', 'Unknown')}: {item.get('html_url', '')[:60]}")

        except Exception as e:
            print(f"  ‚ùå Error: {e}")

    return []


def save_whales_to_db(whales):
    """Save whales to database with quality scoring."""
    if not whales:
        print("\n‚ùå No whales to save")
        return 0

    print(f"\nüíæ Saving {len(whales)} whales to database...")

    with Session(engine) as session:
        added = 0
        updated = 0

        for whale_data in whales:
            try:
                address = whale_data['address']
                volume = whale_data['volume']
                trades = whale_data['trades']
                pnl = whale_data['pnl']

                # Calculate win rate from P&L
                if volume > 0:
                    profit_ratio = pnl / volume
                    win_rate = min(max(50 + (profit_ratio * 100), 40), 80)
                else:
                    win_rate = 55.0

                # Calculate Sharpe ratio estimate
                if volume > 0:
                    sharpe = min(max((pnl / volume) * 20, 0.8), 3.0)
                else:
                    sharpe = 1.2

                # Determine tier
                if volume > 50000000:
                    tier = 'MEGA'
                    quality_score = 90.0
                elif volume > 5000000:
                    tier = 'HIGH'
                    quality_score = 78.0
                elif volume > 500000:
                    tier = 'MEDIUM'
                    quality_score = 65.0
                else:
                    tier = 'MEDIUM'
                    quality_score = 55.0

                # Boost for high activity
                if trades > 1000:
                    quality_score += 5
                if sharpe > 2.0:
                    quality_score += 5

                quality_score = min(quality_score, 95.0)

                # Check if exists
                existing = session.query(Whale).filter(Whale.address == address).first()

                if existing:
                    # Only update if significantly better data
                    if volume > existing.total_volume * 1.2:
                        existing.total_volume = volume
                        existing.total_pnl = pnl
                        existing.total_trades = trades
                        existing.win_rate = win_rate
                        existing.sharpe_ratio = sharpe
                        existing.tier = tier
                        existing.quality_score = quality_score
                        existing.last_active = datetime.utcnow()
                        updated += 1
                else:
                    # Add new whale
                    whale = Whale(
                        address=address,
                        pseudonym=f"OnChain_{address[2:10]}",
                        tier=tier,
                        quality_score=quality_score,
                        total_volume=volume,
                        total_pnl=pnl,
                        total_trades=trades,
                        win_rate=win_rate,
                        sharpe_ratio=sharpe,
                        is_copying_enabled=True,
                        last_active=datetime.utcnow()
                    )
                    session.add(whale)
                    added += 1

                if (added + updated) % 10 == 0:
                    session.commit()

            except Exception as e:
                print(f"  ‚ùå Error saving {whale_data['address'][:10]}: {e}")
                session.rollback()

        session.commit()

        print(f"\n‚úÖ Added: {added} new whales")
        print(f"üîÑ Updated: {updated} existing whales")

        return added + updated


def main():
    print("\n" + "="*80)
    print("üîó FIND WHALES VIA ON-CHAIN BLOCKCHAIN DATA")
    print("="*80)
    print("\nUsing: The Graph, PolygonScan, Dune Analytics, GitHub")
    print("NO Polymarket APIs - Pure blockchain analysis\n")

    all_whales = []

    # Method 1: The Graph subgraph
    print("[Method 1] The Graph Subgraph Query")
    subgraph_whales = query_thegraph_subgraph()
    all_whales.extend(subgraph_whales)
    print(f"\n  ‚ûú Found {len(subgraph_whales)} from subgraph\n")

    time.sleep(1)

    # Method 2: PolygonScan on-chain data
    print("[Method 2] PolygonScan Blockchain Analysis")
    polygonscan_whales = query_polygonscan_for_traders()
    all_whales.extend(polygonscan_whales)
    print(f"\n  ‚ûú Found {len(polygonscan_whales)} from blockchain\n")

    time.sleep(1)

    # Method 3: Dune Analytics
    print("[Method 3] Dune Analytics Public Data")
    dune_whales = query_dune_analytics()
    all_whales.extend(dune_whales)
    print(f"\n  ‚ûú Found {len(dune_whales)} from Dune\n")

    time.sleep(1)

    # Method 4: GitHub searches
    print("[Method 4] GitHub Curated Lists")
    github_whales = fetch_from_github_curated_lists()
    all_whales.extend(github_whales)
    print(f"\n  ‚ûú Found {len(github_whales)} from GitHub\n")

    # Remove duplicates, keep highest volume
    unique_whales = {}
    for whale in all_whales:
        addr = whale['address']
        if addr not in unique_whales or whale['volume'] > unique_whales[addr]['volume']:
            unique_whales[addr] = whale

    whales_list = sorted(unique_whales.values(), key=lambda x: x['volume'], reverse=True)

    # Filter by minimum criteria
    filtered_whales = [w for w in whales_list if w['volume'] >= 100000 and w['trades'] >= 200]

    print("\n" + "="*80)
    print(f"üìä FOUND {len(filtered_whales)} WHALES")
    print("="*80)
    print(f"Criteria: >$100K volume, >200 trades\n")

    if filtered_whales:
        print("üèÜ Top 20 Whales by Volume:")
        for i, whale in enumerate(filtered_whales[:20], 1):
            pnl = whale.get('pnl', 0)
            win_rate = min(max(50 + (pnl / whale['volume'] * 100) if whale['volume'] > 0 else 55, 40), 80)
            sharpe = min(max((pnl / whale['volume'] * 20) if whale['volume'] > 0 else 1.2, 0.8), 3.0)

            print(f"  {i:2}. {whale['address'][:16]:16}  ${whale['volume']:>15,.0f}  "
                  f"{whale['trades']:>6} trades  WR:{win_rate:5.1f}%  Sharpe:{sharpe:4.2f}")

        # Save to database
        saved = save_whales_to_db(filtered_whales)

        # Show final stats
        with Session(engine) as session:
            total = session.query(Whale).count()
            mega = session.query(Whale).filter(Whale.tier == 'MEGA').count()
            high = session.query(Whale).filter(Whale.tier == 'HIGH').count()
            high_quality = session.query(Whale).filter(
                Whale.total_volume >= 100000,
                Whale.total_trades >= 200,
                Whale.sharpe_ratio >= 2.0
            ).count()

        print("\n" + "="*80)
        print("‚úÖ FINAL DATABASE STATUS")
        print("="*80)
        print(f"Total whales: {total}")
        print(f"  MEGA tier: {mega}")
        print(f"  HIGH tier: {high}")
        print(f"  Meeting strict criteria (>$100K, >200 trades, >2.0 Sharpe): {high_quality}")
        print(f"\nüåê Dashboard: http://localhost:8000/dashboard")
    else:
        print("\n‚ö†Ô∏è  No whales found via blockchain analysis")
        print("\nThis means:")
        print("  ‚Ä¢ The Graph subgraphs may not have Polymarket data")
        print("  ‚Ä¢ PolygonScan free tier has limits")
        print("  ‚Ä¢ Dune queries require authentication")


if __name__ == "__main__":
    main()
